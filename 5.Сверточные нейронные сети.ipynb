{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание**<a id='toc0_'></a>    \n",
    "- [Свёртка, каскад свёрток](#toc1_)    \n",
    "    - [Свертка](#toc1_1_1_)    \n",
    "    - [Пуллинг](#toc1_1_2_)    \n",
    "- [Собери их всех: архитектура LeNet (1998)](#toc2_)    \n",
    "- [Собери их все: AlexNet (2012) и VGG (2014)](#toc3_)    \n",
    "  - [AlexNet](#toc3_1_)    \n",
    "    - [Почему ReLU. Потому что затухание градиента](#toc3_1_1_)    \n",
    "  - [VGG](#toc3_2_)    \n",
    "- [Собери их все: GoogLeNet и ResNet (2015)](#toc4_)    \n",
    "  - [Inception block](#toc4_1_)    \n",
    "    - [Bottle neck](#toc4_1_1_)    \n",
    "  - [GoogLeNet](#toc4_2_)    \n",
    "  - [Residual Block](#toc4_3_)    \n",
    "  - [ResNet](#toc4_4_)    \n",
    "- [Итого](#toc5_)    \n",
    "- [Теоретические задачи: архитектуры сверточных нейронных сетей](#toc6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Свёртка, каскад свёрток](#toc0_)\n",
    "\n",
    "Почему нельзя обойтись полносвязной сетью, ведь\n",
    "\n",
    "- сигмоидные полносвязанные нейронные сети полны. При помощи них можно восстановить любую зависимость с любой точностью\n",
    "\n",
    "Потому что \n",
    "- у нас ограниченные вычислительные возможности\n",
    "  - если полносвязная сеть научилась аппроксимировать (сигмоидами) векторное представление кота по центру кадра, то кота в углу кадра она все равно не увидит\n",
    "  - поэтому нужны обучающие образцы для всех возможных размещений объекта в кадре\n",
    "  - или нужны дополнительные маски для кодирования размещения объектов в кадре\n",
    "- нужно использовать дополнительную информацию о структуре данных\n",
    "  - часто требуется использовать информацию о структуре данных, то есть - \"какой пиксель находится рядом с каким\"\n",
    "\n",
    "**Операция свертки инварианта для расположения объекта в кадре**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Свертка](#toc0_)\n",
    "\n",
    "Ядром свертки проходим по данным. Ядро множится по-элементно на фрагмент, результат суммируется, если это нейросеть - еще добавляется смещение, записывается в сверточную матрицу такой же или меньшей (или большей, если паддинг больше половины ядра) размерности.\n",
    "- есть несколько основных параметров (**padding, strides, dilation**)\n",
    "- [идеальная иллюстрация](https://github.com/vdumoulin/conv_arithmetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть матрица признаков равна [[4, 2, -1],[-6, 0, 5],[3, 2, 2]], а ядро свертки -- [[0, 1, 2],[1, -1, 0],[1, 0, -2]]\n",
    "\n",
    "Каков будет результат применения свертки со `stride=2, padding=1`\n",
    "\n",
    "\\*) 2д свертка значит матрица ядра двухмерная\n",
    "\n",
    "**Примерное АПИ сверток торча:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.,  3.],\n",
       "          [-9.,  5.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# добавляется 1 измерение для каналов, 1 измерение для батчей\n",
    "X = torch.tensor([[4, 2, -1],[-6, 0, 5],[3, 2, 2]]).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "ker = torch.tensor([[0, 1, 2],[1, -1, 0],[1, 0, -2]]).float()\n",
    "\n",
    "# добавляется 1 измерение для ВХОДНЫХ каналов, 1 измерение для ВЫХОДНЫХ каналов\n",
    "fltr = ker.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "conv = torch.nn.Conv2d(in_channels=1, \n",
    "                       out_channels=1, \n",
    "                       kernel_size=ker.shape, \n",
    "                       padding=1, \n",
    "                       stride=2, \n",
    "                       bias=False)              # для порядка аргументы по именам\n",
    "\n",
    "conv.weight.data = torch.nn.Parameter(fltr)     # для порядка, обычно это настраиваевоеваемый параметр\n",
    "\n",
    "conv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы работаем с изображениями -- изображения, как правило, трёхканальные. Для каждого из этих цветов есть некоторая матрица, которая описывает, сколько зелёного, красного и синего цвета в каждом пикселе. Как свёртка работает в этом случае? В случае с трёхканальными изображениями ядро свёртки -- это трёхмерная табличка, а не двумерная, как в предыдущем случае.\n",
    "\n",
    "**3 входных канал - 1 фильтр (3 канальный, т.е. 3 ядра) - 1 выходной канал**\n",
    "\n",
    "<img src=\"./img/conv3d.png\" width=\"500\">\n",
    "\n",
    "Например: в свертке размером 3х3, которая применяется к трехканальному изображению (не считая слой активации, не учитывая bias) будет 27 параметров: 3х3 для каждого из трех каналов\n",
    "\n",
    "Следующие сверточные слои могут быть более витееватыми\n",
    "\n",
    "**N входных каналов - M фильтров (N канальных) - M выходных каналов**\n",
    "\n",
    "<img src=\"./img/NMconv3d.png\" width=\"500\">\n",
    "\n",
    "N входных каналов - это уже не обязательно цветовые каналы, а может быть результаты предыдущего слоя сверток.\n",
    "\n",
    "Например: пусть размер матрицы признаков = 4(высота)х5(ширина)x2(кол-во каналов), размеры ядра свертки = 3x3, stride=2, padding=1, количество выходных фильтров = 8. Один 2-канальный фильтр даст матрицу 2х3, таких фильтров 8 -> 6*8=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"Прежде чем мы углубимся в это, я просто хочу провести четкое различие между терминами «ядро» и «фильтр», потому что я видел, что многие люди используют их взаимозаменяемо. Ядро, как описано ранее, представляет собой матрицу весов, которые умножаются на входные данные для извлечения соответствующих признаков. Размеры матрицы ядра как свертка получает свое имя, Например, в двумерных свертках матрица ядра является двумерной матрицей.\n",
    "\n",
    "    Однако фильтр представляет собой объединение нескольких ядер, каждое из которых назначено определенному каналу ввода. Фильтры всегда на одно измерение больше, чем ядра. Например, в двумерных свертках фильтры являются трехмерными матрицами (что по существу является объединением двумерных матриц, то есть ядер). Таким образом, для слоя CNN с размерами ядра h * w и входными каналами k размеры фильтра k * h * w\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Пуллинг](#toc0_)\n",
    "\n",
    "Проследив принцип работы биологического мозга, учёные смогли разработать математический аппарат для извлечения свойств.\n",
    "Оценив общее количество слоёв и свойств, которые нужно проанализировать для отслеживания сложных геометрических форм, можно показать, что количество необходимых вычислительных ресурсов растёт экспоненциально вместе с ростом количества свойств. Для решения этой проблемы была разработана методика пулинга (pooling). Её идея очень проста: если некая область содержит ярко выраженные свойства, то мы можем отказаться от поиска других свойств в этой области (с)\n",
    "\n",
    "Часто используется **max-pooling** - данные делятся на подобласти и выбираются максимумы. \n",
    "\n",
    "Часто для этого выбирается фильтр 2х2:\n",
    "\n",
    "$${\\displaystyle f_{X,Y}(S)=\\max _{a,b=0}^{1}S_{2X+a,2Y+b}.}$$\n",
    "\n",
    "**Для обратного прохода**: градиент равен 1, обратный проход только через ячейку с максимумом\n",
    "\n",
    "Часто испольщуемым вариантом макспуллинга является `RoI-pooling` (Region of Interest), где пуллинг выполняется только в заданном участке данных, поделенном на заданные подучастки (такое деление - это гиперпараметр метода), например это может быть некоторая область кадра и некоторые ее подобласти.\n",
    "\n",
    "\\*) Кроме того, может использоваться и другая метрика для пуллинга (минимум, среднее, $L_2$-норма), но это редко и часто хуже работает.\n",
    "\n",
    "**Пуллинг выполняется для каждого канала независимо, количество каналов не меняется!**\n",
    "\n",
    "Мы исходим из того, что большие значения после свертки несут большую часть информации, поэтому выкидываем 3/4 информации как шум (для пулинга 2х2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Собери их всех: архитектура LeNet (1998)](#toc0_)\n",
    "\n",
    "Предложена для распознавания рукописных цифр. LeNet решает задачу, которая называется MNIST. Эта задача заключается в том, что нам нужно верно классифицировать на десять классов рукописные цифры (от 0 до 9).\n",
    "\n",
    "<img src=\"./img/lenet.png\" width=\"700\">\n",
    "\n",
    "- Вход: 32х32, 1 канал\n",
    "\n",
    "1 слой:\n",
    "- Свертка: 5х5, 6 выходных каналов, без паддинга, шаг 1 (stride)\n",
    "  - 6х28х28\n",
    "- Макс-пуллинг: 2х2\n",
    "  - 6х14х14\n",
    "- Активация тангенсом (-1, 1)\n",
    "  - 6х14х14\n",
    "\n",
    "2 слой:\n",
    "- Свертка: 5х5, 16 выходных каналов, без паддинга, шаг 1 (stride)\n",
    "  - 16х10х10\n",
    "- Макс-пуллинг: 2х2\n",
    "  - 16х5х5\n",
    "- Активация тангенсом (-1, 1)\n",
    "  - 16х5х5\n",
    "\n",
    "3 вытягивание в строку (flatten - одномеризация): 16х5х5 -> 1x1x400\n",
    "\n",
    "Пачка полносвязных слоев:\n",
    "- 400х120 + тангенс\n",
    "- 120х84 + тангенс\n",
    "- 84х10 + софтмакс\n",
    "\n",
    "Получили 10 вероятностей каждого класса (цифр)\n",
    "\n",
    "**Обучение:**\n",
    "\n",
    "Что обучается в сверточных сетях?\n",
    "- Обучаются фильтры сверток и их смещения\n",
    "- Обучаются полносязные слои (матрицы линейного преобразования: веса/смещения)\n",
    "\n",
    "Функция потерь:\n",
    "- кросс-энтропия, т.к. у нас вероятности классов\n",
    "\n",
    "Оптимизатор:\n",
    "- SDGM или Adam\n",
    "  - lr=3e-4, $\\beta_1 =0.9$, $\\beta_1 =0.999$\n",
    "\n",
    "<img src=\"./img/lenet2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Собери их все: AlexNet (2012) и VGG (2014)](#toc0_)\n",
    "\n",
    "MNIST это скорее чисто учебная задача.\n",
    "\n",
    "Более сложная задача **ImageNet 1000**. Это довольно большая база данных с изображениями (15 млн.), которые нужно классифицировать на 1000 классов. База шумная, фактически только 1.5 млн. действительно относятся к этим 1000 классов.\n",
    "\n",
    "Эта задача часто рассматривается как референсная для оценки качества нейросети.\n",
    "\n",
    "## <a id='toc3_1_'></a>[AlexNet](#toc0_)\n",
    "\n",
    "<img src=\"./img/alexnet.png\" width=\"700\">\n",
    "\n",
    "- Вход: 224х224, 3 канала\n",
    "  - если ч/б, то один канал просто дублируется 3 раза\n",
    "  - если разрешение !=224х224, то кадр масштабируется билинейной интерполяцией до 256х256 и берется случайный фрагмент 224х224\n",
    "  - в некоторых источниках пишут 227х227\n",
    "\n",
    "Сверточные слои:\n",
    "- Свертка: 11х11, 96 выходных каналов, шаг 4 (stride)\n",
    "  - паддинг (подбирается по принятому размеру входа, чтоб получилось 55: 5 если 227, 2 если 224)\n",
    "  - 96х55х55\n",
    "- Свертка: 5х5, 256 выходных каналов, шаг 1, паддинг 2 + макс-пуллинг 2х2\n",
    "  - паддинг - аналогично, чтоб на выходе было 27х27\n",
    "  - 256х27х27\n",
    "- Свертка: 3х3, 384 выходных каналов, шаг 1, паддинг 1 + макс-пуллинг 2х2\n",
    "  - паддинг - аналогично, чтоб на выходе было 13х13\n",
    "  - 384х13х13\n",
    "\n",
    "- **Свертка: 3х3**, 384 выходных каналов, шаг 1, паддинг 1\n",
    "  - паддинг - аналогично, чтоб на выходе было 13х13\n",
    "  - 384х13х13\n",
    "- **Свертка: 3х3**, 256 выходных каналов, шаг 1, паддинг 1\n",
    "  - паддинг - аналогично, чтоб на выходе было 13х13\n",
    "  - 256х13х13\n",
    "\n",
    "\\*) после каждого сверточного слоя м.б. еще дополнительно функция активации **ReLU**, а может и не быть...\n",
    "\n",
    "- Макс-пуллинг с шагом 2 (страйд)\n",
    "  - 256х6х6\n",
    "\n",
    "- flatten - одномеризация: 256х6х6 -> 1x1x9216\n",
    "\n",
    "Пачка полносвязных слоев:\n",
    "- 9216х4096 + Relu\n",
    "- 4096х4096 + Relu\n",
    "- 4096х1000 + Softmax\n",
    "\n",
    "Получили 1000 вероятностей каждого класса\n",
    "\n",
    "**Обучение:**\n",
    "\n",
    "Функция потерь:\n",
    "- кросс-энтропия, т.к. у нас вероятности классов\n",
    "\n",
    "Оптимизатор:\n",
    "- SDGM или Adam\n",
    "\n",
    "**Фишка:**\n",
    "- свертки 3х3 без макс-пуллинга были предложены в оригинальной статье и обусловлены тем, что у авторов комп не потянул в этом месте еще одну свертку 5х5. Вместо этого сделали каскад сверток 3х3. Так они решили расширить рецептивное поле сверток и так и осталось.\n",
    "  - Свертка 5х5 это 5x5+bias=26 обучаемых параметров, две свертки 3х3 это 3х3+1+3х3+1=20 обучаемых параметров\n",
    "\n",
    "### <a id='toc3_1_1_'></a>[Почему ReLU. Потому что затухание градиента](#toc0_)\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}\\\\\n",
    "\\sigma' = \\sigma(1-\\sigma) \\leq \\frac{1}{4} \\to 0$$\n",
    "\n",
    "Если у нас сеть из $n$ сигмоид, то производная фукнции потерь ограничена $\\frac{1}{4}^n$ и с учетом ограниченной вычислительной точности все быстро сравнивается с 0. Это называется **затухание градиента**. Глубокие слои перестают обучаться, т.к. производная до них просто не доходит при обратном распространении.\n",
    "\n",
    "Частично это решается гипертангенсом (иногда его тоже зовут сигмоидой):\n",
    "\n",
    "$$\\sigma^*(x) = \\frac{e^{x}-e^{-x}}{e^{x}-e^{-x}}\\\\\n",
    "\\sigma' = (1+\\sigma)(1-\\sigma) \\leq 1$$\n",
    "\n",
    "- частично, потому что областях плато (-1, 1) производная $\\to 0$\n",
    "- при обратном распространении ошибки такие производные все равно зануляют градиент\n",
    "\n",
    "*Почему бы тогда не брать просто линейные функции активации?* А потому, что многослойная сеть тогда будет эквивалентна однослойной полносвязной сети, т.е. просто одному линейному преобразованию.\n",
    "\n",
    "*Почему бы тогда просто не домножать градиент просто на достаточно большое число, если он уходит в 0?* Тогда это не будет градиент нужной нам функции потерь, а просто некоторое направление, которое возможно и будет коррелировать с истинным градиентом, но не факт.\n",
    "\n",
    "**Что дает ReLU (rectified linear unit)**\n",
    "\n",
    "$$ReLU(x) = \\begin{cases} \n",
    "0, & x < 0 \\\\\n",
    "x, & x \\geq 0\n",
    "\\end{cases}$$\n",
    "\n",
    "Как вариант ELU (exponential linear unit)\n",
    "$$ELU(x) = \\begin{cases} \n",
    "e^x - 1, & x < 0 \\\\\n",
    "x, & x \\geq 0\n",
    "\\end{cases}$$\n",
    "\n",
    "Как вариант Leaky ReLU\n",
    "$$Leaky-ReLU(x) = \\begin{cases} \n",
    "\\alpha x, & x < 0 \\\\\n",
    "x, & x \\geq 0\n",
    "\\end{cases}$$\n",
    "\n",
    "Как вариант SeLU\n",
    "$$SeLU(x) = \\begin{cases} \n",
    "\\alpha e^x - \\alpha, & x < 0 \\\\\n",
    "x, & x \\geq 0\n",
    "\\end{cases}$$\n",
    "\n",
    "- обучаемый параметр $\\alpha$\n",
    "\n",
    "Каскад таких функций будет обращаться в 0 только если производная =0. Но если сеть достаточно глубокая, то вероятность, что на каком-то из слоев градиент затухнет и перестанет распространяться дальше, все равно довольно высокая, хотя такой прямой зависимости от количества слоев, как у сигмоиды, тут уже нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[VGG](#toc0_)\n",
    "\n",
    "По названию компании Visual Geometry Group\n",
    "\n",
    "<img src=\"./img/vgg.png\" width=\"500\">\n",
    "\n",
    "Суть в том, что чтобы избежать затухания градиента и долгого обучения сначала обучается простая модель A, потом к ней добавляются слой B. \n",
    "\n",
    "Если градиет затухнет, то глубокие слои уже обучены. \n",
    "\n",
    "**Фишки:**\n",
    "\n",
    "- В слое С добавляется фиктивная свертка 1х1, чтобы остальные уже обученные параметры сети адаптировались, что есть еще слои. Потом он заменяется на свертку 3х3, которая дообучается уже сама по себе\n",
    "\n",
    "- Для увеличения рецептивного поля используются каскады сверток между макс-пуллингами\n",
    "\n",
    "Часто такая архитектура используется в качестве базовой (backbone) для решения других задач, не связанных с ImageNet, путем добавления и замены выходных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Собери их все: GoogLeNet и ResNet (2015)](#toc0_)\n",
    "\n",
    "## <a id='toc4_1_'></a>[Inception block](#toc0_)\n",
    "\n",
    "<img src=\"./img/inception.png\">\n",
    "\n",
    "Идея inception блока состоит в том, что возможно, что мы хотим сделать не одну операцию к входу, например, свёртку, а несколько разных и посмотреть, каков будет результат их применения.\n",
    "\n",
    "Inception блок делает параллельно несколько операций. Главное, чтобы результат всех параллельных блоков операций имел одинаковый выходной размер (например, кадр размером 128х128). Количество выходных каналов может быть разным. \n",
    "\n",
    "После этого все результаты всех параллельных блоков конкатенируются, получается тензор размером (сумма выходных каналов разных преобразований x размер кадра)\n",
    "\n",
    "### <a id='toc4_1_1_'></a>[Bottle neck](#toc0_)\n",
    "\n",
    "В примере мелькают свертки 1х1. Это прием для уменьшения количества каналов, если нас устраивает примерный результат. Например вместо свертки 5х5 с 2048 вх/вых.каналами можно пройтись сверткой 1х1 с 512 вых.каналами (уменьшить число каналов в 4 раза), а потом пройтись сверткой 5х5 с 512 вх. и 2048 вых. каналами. Число операций уменьшается в 4 раза. Результат обычно почти не отличается на больших размерностях.\n",
    "\n",
    "Например, если у нас имеется кадр RGB с тремя каналами, и мы к нему применим свёртку 1х1 с 1 выходным каналом,  то в результате получим кадр того же размера, но с одним каналом. В нём показатели RGB некоторой лин.комбинацией входных каналов (зависит от ядра свертки). Для таких малых размерностей смысла нет делать bottle neck.\n",
    "\n",
    "К свертке 1х1 может добавляться также функция активации, что эквивалентро применению этой функции ко всем пикселям кадра.\n",
    "\n",
    "Т.о. свёртка 1х1 - это просто умножение всех пикселей на одинаковый вес и добавление смещения (сеть может выучить нормализацию) и пропускание выхода через нелинейность. Это также помогает получить меньше кода, чем если писать все эти операции по-отдельности - просто сделать свёртку 1х1.\n",
    "\n",
    "## <a id='toc4_2_'></a>[GoogLeNet](#toc0_)\n",
    "\n",
    "Сеть, состоящая из Inception blocks\n",
    "\n",
    "<img src=\"./img/googlenet.png\">\n",
    "\n",
    "Сеть достаточно глубокая. И чтобы градиент не затухал к слоям подключены дополнительные вспомогательные выходные слои, от которых распространяется дополнительный градиент функции ошибок.\n",
    "- для значений истинных классов в дополнительных выходах используются те же метки, что и у основного.\n",
    "\n",
    "В оригинальной архитектуре таких вспомогательных выходных слоев два (кроме основного)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[Residual Block](#toc0_)\n",
    "\n",
    "Придумали в миклосохте\n",
    "\n",
    "<img src=\"./img/resblock.png\">\n",
    "\n",
    "Вход в некоторую свертку $x$ обрабатывается функцией $F(x)$ и на выход из блока выдается их сумма $F(x)+x$. То есть добавляется связь в обход свертки (residual connection).\n",
    "\n",
    "$$ y = F(x) + x \\\\\n",
    "y' = F'(x) + 1 \\\\\n",
    "\n",
    "\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial x} = \\frac{\\partial L}{\\partial y}[F'(x) + 1 ]$$\n",
    "\n",
    "Т.е. градиент не затухает, информация проходит частично в обход.\n",
    "\n",
    "Тут также часто применяют свертки 1х1 для экономии вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_4_'></a>[ResNet](#toc0_)\n",
    "\n",
    "<img src=\"./img/resnet.png\">\n",
    "\n",
    "Схема оригинальной архитектуры для ImageNet\n",
    "\n",
    "На схеме ResNet блоки, в которых происходит уменьшение размера картинки в два раза, нарисованы с пунктирной дугой. Как там происходит прибавление входного х к выходному f(x)? Эти тензоры имеют разный shape, поэтому\n",
    "- есть несколько способов уменьшить на этих residual connections размер в два раза. Один из вариантов - сделать свертку Conv2d(C, 2C, kernel_size=(1, 1), stride=(2, 2)). Есть и много других. Ну, например, можно сделать average pooling 2x2 и дважды продублировать каналы.\n",
    "\n",
    "**Фишка:**\n",
    "- на выходе нет полносвязных слоев, т.к. сеть достаточно глубокая и предполагается, что оптимальная линейная комбинация активационных функций уже найдена в виде сверточных слоев и обходных связей (очень глубокие сети имеют тенденцию отлично дискриминировать объекты и без FC-слоёв).\n",
    "- для решения конкретных задач могут добавляться выходные полносвязные слои, например для ImageNet1000 это будет AvgPooling + FC1000\n",
    "\n",
    "Модификации сети отличаются количеством слоев, распространенные конфигурации \n",
    "- Resnet-18, \n",
    "- ResNet-32, \n",
    "- ... \n",
    "- ResNet-1024\n",
    "\n",
    "Обычно вход такой сети - кадры 224х224. Это исторически сложившийся размер, к которому часто приводят другие размеры кадра.\n",
    "- но можно подавать любой размер, желательно кратный 32, т.к. 5 раз происходит сжатие кадра в 2 раза (слои /2 на схеме), либо отбрасывать лишнее или дополнять 0 до кратного 32\n",
    "\n",
    "ResNet уже неважно, сколько пикселей во входном изображении, важен масштаб деталей.\n",
    "- в конце сети тензор усредняется и таким образом масштабируется до размера полносвязанного слоя\n",
    "- мы усредняемся и не важно по какой базе (7х7, 32х32 да хоть 1024х1024, сколько дошло до конца от размера исходного кадра) важно то, что мы всё свели постоянному количеству 512 выходных каналов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Итого](#toc0_)\n",
    "\n",
    "LeNet (1998)\n",
    "- функция активации tanh, свёрточные слои и пулинг\n",
    "\n",
    "AlexNet (2012)\n",
    "- каскад свёрток (увеличение receptive field) и функция активации ReLU\n",
    "\n",
    "VGG (2014)\n",
    "- обучать урезанную версию сети, постепенно добавляя слои, а также свёртки 1х1\n",
    "\n",
    "GoogLeNet (2015)\n",
    "- слои, где собирается тензор из нескольких свёрток разного размера\n",
    "\n",
    "ResNet (2015)\n",
    "- обходные соединения, пробрасывающие градиент ошибки в обход свёртки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Теоретические задачи: архитектуры сверточных нейронных сетей](#toc0_)\n",
    "\n",
    "Рассмотрим некоторую нейронную сеть $y = f(x)$, где $y$ и $x$ - тензоры.\n",
    "\n",
    "Пусть тензор $x$ имеет размер $N \\times C \\times H \\times W$, а тензор $y$ имеет размер $N \\times C' \\times H' \\times W'$.\n",
    "\n",
    "Рассмотрим некоторый подтензор : $\\texttt{y[n, :, a, b]}$, где $\\texttt{n, a, b}$ - некоторые координаты в тензоре \n",
    "\n",
    "$$y: 0 \\leq \\texttt{n} \\leq N - 1,\\\\ 0 \\leq \\texttt{a} \\leq H' - 1, \\\\ 0 \\leq \\texttt{b} \\leq W'-1$$\n",
    "\n",
    "Этот вектор зависит от некоторого подтензора входного тензора $x: \\texttt{x[n, :, a':a'+h, b':b'+w]}$. То есть, если поменять хотя бы одно значение в этом подтензоре, то результат может измениться, вне этого подтензора любые изменения не изменят вектор $\\texttt{y[n, :, a, b]}$.\n",
    "\n",
    "Размеры этого тензора h, w называются receptive field или **пятном восприятия**.\n",
    "\n",
    "Найдите receptive field для следующей подсети:\n",
    "\n",
    "    torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=C, out_channels=C, kernel_size=(3, 1)),\n",
    "        torch.nn.Conv2d(in_channels=C, out_channels=C, kernel_size=(1, 3))\n",
    "    )\n",
    "\n",
    "**RF = (3, 3)**\n",
    "\n",
    "    torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=C, out_channels=C, kernel_size=(3, 3)),\n",
    "        torch.nn.Conv2d(in_channels=C, out_channels=C, kernel_size=(3, 3))\n",
    "    )\n",
    "\n",
    "**RF = (5, 5)**\n",
    "\n",
    "    torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=C, out_channels=C, kernel_size=(5, 5), stride=(2, 2)),\n",
    "        torch.nn.Conv2d(in_channels=C, out_channels=C, kernel_size=(5, 5))\n",
    "    )\n",
    "\n",
    "**RF = (13, 13)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим две нейронные сети:\n",
    "\n",
    "1:\n",
    "\n",
    "    torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(2 * С, 2 * С, kernel_size=(3, 3), padding=1, bias=False)\n",
    "    )\n",
    "\n",
    "2:\n",
    "\n",
    "    torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(2 * С, С, kernel_size=(1, 1), bias=False),\n",
    "        torch.nn.Conv2d(С, С, kernel_size=(3, 3), padding=1, bias=False),\n",
    "        torch.nn.Conv2d(С, 2 * С, kernel_size=(1, 1), bias=False)\n",
    "    )\n",
    "    \n",
    "Найдите отношение количества параметров первой сети к количеству параметров во второй сети.\n",
    "\n",
    "Убедитесь в том, что количество операций для некоторого входного тензора размером $N \\times 2C \\times H \\times W$ соотносится так же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.769230769230769"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "C = 1\n",
    "c1 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(2 * C, 2 * C, kernel_size=(3, 3), padding=1, bias=False)\n",
    "    )\n",
    "    \n",
    "list(c1.parameters())   # 3*3*4\n",
    "\n",
    "c2 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(2 * C, C, kernel_size=(1, 1), bias=False),\n",
    "        torch.nn.Conv2d(C, C, kernel_size=(3, 3), padding=1, bias=False),\n",
    "        torch.nn.Conv2d(C, 2 * C, kernel_size=(1, 1), bias=False)\n",
    "    )\n",
    "\n",
    "\n",
    "list(c2.parameters())   # 2 + 3*3 + 2\n",
    "\n",
    "3*3*4 / (2 + 3*3 + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим граф вычисления, который состоит из $N$ блоков, следующих друг за другом:\n",
    "\n",
    "![alt text](./img/task.svg)\n",
    "\n",
    "Допустим, что мы знаем производную лосс-функции $L$ по выходу из последнего блока $x_N$ ($\\frac{\\partial L}{\\partial x_N}$). Найдите производную $\\frac {\\partial L}{\\partial x_0}$, если известны все производные $\\frac{\\partial f_{i}}{\\partial x_i}$.\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_0} = \\frac{\\partial L}{\\partial x_1} \\frac{\\partial x_1}{\\partial x_0}  = \\frac{\\partial L}{\\partial x_1} \\frac{\\partial f_0}{\\partial x_0} \\\\\n",
    "...\\\\\n",
    "\\frac{\\partial L}{\\partial x_0} = \\frac{\\partial L}{\\partial x_N} \\prod_{i=0}^N \\frac{\\partial f_i}{\\partial x_i} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим граф вычисления, который состоит из $N$ блоков, следующих друг за другом следующего вида:\n",
    "\n",
    "![alt text](./img/task_res.png)\n",
    "\n",
    "Допустим, что мы знаем производную лосс-функции $L$ по выходу из последнего блока $x_N$ ($\\frac{\\partial L}{\\partial x_N}$). Найдите производную $\\frac {\\partial L}{\\partial x_0}$, если известны все производные $\\frac{\\partial f_{i}}{\\partial x_i}$.\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_0} = \\frac{\\partial L}{\\partial x_1} \\frac{\\partial x_1}{\\partial x_0}  = \\frac{\\partial L}{\\partial x_1} \\frac{\\partial (f_0 + x_0)}{\\partial x_0} =  \\frac{\\partial L}{\\partial x_1} (\\frac{\\partial f_0}{\\partial x_0} + 1)\\\\\n",
    "...\\\\\n",
    "\\frac{\\partial L}{\\partial x_0} = \\frac{\\partial L}{\\partial x_N} \\prod_{i=0}^N (\\frac{\\partial f_i}{\\partial x_i} + 1) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим граф вычисления, который состоит из $N$ блоков, следующих друг за другом:\n",
    "\n",
    "![alt text](./img/task.svg)\n",
    "\n",
    "Допустим, что мы знаем производную лосс-функции $L$ по выходу из последнего блока $x_N$ ($\\frac{\\partial L}{\\partial x_N}$). Допустим, что все производные $\\left| \\frac{\\partial f_{i}}{\\partial x_i}\\right| \\leq 0.5$. Найдите, каким значением будет ограничено сверху значение $\\left|\\frac{\\partial L}{\\partial x_{0}}\\right|$.\n",
    "\n",
    "$$|\\frac{\\partial L}{\\partial x_0}| \\leq |\\frac{\\partial L}{\\partial x_N}| 0.5^N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим граф вычисления, который состоит из $N$ блоков, следующих друг за другом:\n",
    "\n",
    "![alt text](./img/task_res.png)\n",
    "\n",
    "Допустим, что мы знаем производную лосс-функции $L$ по выходу из последнего блока $x_N$ ($\\frac{\\partial L}{\\partial x_N}$). Допустим, что все производные $\\left| \\frac{\\partial f_{i}}{\\partial x_i}\\right| \\leq 0.5$. Найдите, каким значением будет ограничено сверху значение $\\left|\\frac{\\partial L}{\\partial x_{0}}\\right|$.\n",
    "\n",
    "$$|\\frac{\\partial L}{\\partial x_0}| \\leq |\\frac{\\partial L}{\\partial x_N}| 1.5^N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим граф вычисления, который состоит из NN блоков, следующих друг за другом:\n",
    "\n",
    "![alt text](./img/task.svg)\n",
    "\n",
    "Допустим, что мы знаем производную лосс-функции $L$ по выходу из последнего блока $x_N$ ($\\frac{\\partial L}{\\partial x_N}$). Пусть существует ненулевая вероятность того, что $\\frac{\\partial f_{i}}{\\partial x_i} = 0$ и она равна $p$. При этом, во всех остальных случаях $\\frac{\\partial f_{i}}{\\partial x_i} = 1$ (ситуация очень похожа на применение ReLU).\n",
    "\n",
    "Найдите вероятность того, что $\\frac{\\partial L}{\\partial x_0} = 0 $.\n",
    "\n",
    "Вероятность 1 и более \"успехов\" в схеме Бернулли с N испытаниями:\n",
    "\n",
    "- равна 1 - вероятность 0 \"успехов\" (ровно 0 \"неудач\") равна $1 - (1-p)^N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим граф вычисления, который состоит из NN блоков, следующих друг за другом:\n",
    "\n",
    "\n",
    "![alt text](./img/task_res.png)\n",
    "\n",
    "Допустим, что мы знаем производную лосс-функции $L$ по выходу из последнего блока $x_N$ ($\\frac{\\partial L}{\\partial x_N}$). Пусть существует ненулевая вероятность того, что $\\frac{\\partial f_{i}}{\\partial x_i} = 0$ и она равна $p$. При этом, во всех остальных случаях $\\frac{\\partial f_{i}}{\\partial x_i} = 1$ (ситуация очень похожа на применение ReLU).\n",
    "\n",
    "Найдите вероятность того, что $\\frac{\\partial L}{\\partial x_0} = 0 $.\n",
    "\n",
    "- это невозможное событие, поэтому вероятность = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Семинар** про классификацию рукописных цифр сверточной сетью в `./Neural_Networks_and_CV`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d00ba0b92f737b23b3e678e3a3ceb3fe4e948ad1ab95d9c6fdcbb4b4ec65f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
