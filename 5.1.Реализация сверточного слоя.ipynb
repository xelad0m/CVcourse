{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание**<a id='toc0_'></a>    \n",
    "- [Свёрточный слой (convolution layer)](#toc1_)    \n",
    "    - [Реализуем функцию, добавляющую padding](#toc1_1_1_)    \n",
    "- [Код тестирования](#toc2_)    \n",
    "- [Сравним скорость](#toc3_)    \n",
    "- [Что внутре у торча в свертке?](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Свёрточный слой (convolution layer)](#toc0_)\n",
    "\n",
    "Свёрточный слой (convolution layer) – центральное понятие в современном компьютерном зрении. Конечно, в PyTorch есть его реализация. Но всегда (?) полезно, чтобы разобраться, запрограммировать его руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Создаем входной массив из двух изображений RGB 3*3\n",
    "input_images = torch.tensor(\n",
    "      [[[[0,  1,  2],\n",
    "         [3,  4,  5],\n",
    "         [6,  7,  8]],\n",
    "\n",
    "        [[9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]],\n",
    "\n",
    "        [[18, 19, 20],\n",
    "         [21, 22, 23],\n",
    "         [24, 25, 26]]],\n",
    "\n",
    "\n",
    "       [[[27, 28, 29],\n",
    "         [30, 31, 32],\n",
    "         [33, 34, 35]],\n",
    "\n",
    "        [[36, 37, 38],\n",
    "         [39, 40, 41],\n",
    "         [42, 43, 44]],\n",
    "\n",
    "        [[45, 46, 47],\n",
    "         [48, 49, 50],\n",
    "         [51, 52, 53]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Реализуем функцию, добавляющую padding](#toc0_)\n",
    "\n",
    "- возьмем готовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding2d(input_images, pad=1):\n",
    "    padded_images = torch.nn.functional.pad(input_images, pad=(pad, ) * 4)\n",
    "    \n",
    "    # варианты\n",
    "    # padder = torch.nn.ZeroPad2d(pad)\n",
    "    # padded_images = padder(input_images)\n",
    "\n",
    "    # s = input_images.shape\n",
    "    # padded_images = torch.zeros(s[:-2] + (s[-2] + 2*pad, s[-1] + 2*pad))\n",
    "    # padded_images[:, :, pad:-pad, pad:-pad] += input_images\n",
    "\n",
    "    # h, w = input_images.shape[-2:]\n",
    "    # A = torch.cat((torch.zeros(pad, h), torch.eye(w + pad, h)), axis=0)\n",
    "    # B = torch.cat((torch.zeros(w, pad), torch.eye(w, h + pad)), axis=1)\n",
    "    # padded_images = A @ input_images.float() @ B\n",
    "\n",
    "    return padded_images.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверточный слой это массив фильтров. Каждый фильтр имеет следующую размерность:\n",
    "\n",
    "- число слоев во входном изображении (для RGB это 3)\n",
    "- высота фильтра\n",
    "- ширина фильтра\n",
    "\n",
    "В ядре (кернеле) все фильтры имеют одинаковые размерность, поэтому ширину и высоту фильтров называют шириной и высотой ядра. Чаще всего ширина ядра равна высоте ядра, в таком случае их называют размером ядра (`kernel_size`).\n",
    "\n",
    "Также слой имеет такие параметры:\n",
    "\n",
    "- `padding` - на какое количество пикселей увеличивать входное изображение с каждой стороны.\n",
    "- `stride` - на сколько пикселей смещается фильтр при вычислении свертки\n",
    "\n",
    "$L_{out} =⌊\\frac{L_{in} +2×padding−dilation×(kernel_{size}−1)−1}{stride} +1⌋$ - для каждого измерения свертки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 10, 8, 8]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "def calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding, dilation=1):\n",
    "    batch_size, in_channels, h_in, w_in = input_matrix_shape\n",
    "\n",
    "    h_out = floor((h_in + 2 * padding - dilation * (kernel_size -1) - 1) / stride + 1)\n",
    "    w_out = floor((w_in + 2 * padding - dilation * (kernel_size -1) - 1) / stride + 1)\n",
    "\n",
    "    out_shape = [batch_size, out_channels, h_out, w_out]\n",
    "    return out_shape\n",
    "\n",
    "calc_out_shape(input_matrix_shape=[2, 3, 10, 10],\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3,\n",
    "                   stride=1,\n",
    "                   padding=0)   # [2, 10, 8, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Код тестирования](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "# абстрактный класс для сверточного слоя\n",
    "class ABCConv2d(ABC):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def set_kernel(self, kernel):\n",
    "        self.kernel = kernel\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, input_tensor):\n",
    "        pass\n",
    "\n",
    "\n",
    "# класс-обертка над torch.nn.Conv2d для унификации интерфейса\n",
    "class Conv2d(ABCConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, dilation=1):\n",
    "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                                      stride, padding=padding, dilation=dilation, bias=False)\n",
    "\n",
    "    def set_kernel(self, kernel):\n",
    "        self.conv2d.weight.data = kernel\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        return self.conv2d(input_tensor)\n",
    "\n",
    "\n",
    "# функция, создающая объект класса cls и возвращающая свертку от input_matrix\n",
    "def create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n",
    "    out_channels = kernel.shape[0]\n",
    "    in_channels = kernel.shape[1]\n",
    "    kernel_size = kernel.shape[2]\n",
    "\n",
    "    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n",
    "    layer.set_kernel(kernel)\n",
    "\n",
    "    return layer(input_matrix)\n",
    "\n",
    "\n",
    "# Функция, тестирующая класс conv2d_cls.\n",
    "# Возвращает True, если свертка совпадает со сверткой с помощью torch.nn.Conv2d.\n",
    "def test_conv2d_layer(conv2d_layer_class, batch_size=2,\n",
    "                      input_height=4, input_width=4, stride=2):\n",
    "    kernel = torch.tensor(\n",
    "                      [[[[0., 1, 0],\n",
    "                         [1,  2, 1],\n",
    "                         [0,  1, 0]],\n",
    "\n",
    "                        [[1, 2, 1],\n",
    "                         [0, 3, 3],\n",
    "                         [0, 1, 10]],\n",
    "\n",
    "                        [[10, 11, 12],\n",
    "                         [13, 14, 15],\n",
    "                         [16, 17, 18]]], #]) \n",
    "                         \n",
    "                        [[[0., 1, 1],\n",
    "                         [1,  2, 1],\n",
    "                         [0,  1, 0]],\n",
    "\n",
    "                        [[1, 2, 1],\n",
    "                         [0, 3, 3],\n",
    "                         [0, 1, 10]],\n",
    "\n",
    "                        [[10, 11, 12],\n",
    "                         [13, 14, 15],\n",
    "                         [16, 17, 18]]]])\n",
    "\n",
    "\n",
    "    in_channels = kernel.shape[1]\n",
    "\n",
    "    input_tensor = torch.arange(0, batch_size * in_channels *\n",
    "                                input_height * input_width,\n",
    "                                out=torch.FloatTensor()) \\\n",
    "        .reshape(batch_size, in_channels, input_height, input_width)\n",
    "\n",
    "    custom_conv2d_out = create_and_call_conv2d_layer(\n",
    "        conv2d_layer_class, stride, kernel, input_tensor)\n",
    "    conv2d_out = create_and_call_conv2d_layer(\n",
    "        Conv2d, stride, kernel, input_tensor)\n",
    "\n",
    "    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n",
    "              and (custom_conv2d_out.shape == conv2d_out.shape)\n",
    "\n",
    "print(test_conv2d_layer(Conv2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Сверточный слой через циклы.\n",
    "class Conv2dLoop(ABCConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride)\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, input_tensor, bias=None):\n",
    "        padded_tensor = get_padding2d(input_tensor, pad=self.padding)\n",
    "        *_, in_height, in_width = padded_tensor.shape\n",
    "\n",
    "        out_shape = calc_out_shape(padded_tensor.shape, \n",
    "                                   self.out_channels, \n",
    "                                   self.kernel_size, \n",
    "                                   self.stride, \n",
    "                                   padding=self.padding, dilation=1)\n",
    "                                   \n",
    "        output_tensor = torch.zeros(out_shape)\n",
    "\n",
    "        for im_idx, image in enumerate(padded_tensor):\n",
    "            for c_in, in_channel in enumerate(image):\n",
    "                for c_out in range(self.out_channels):\n",
    "                    for h_out, h_in in enumerate(range(0, in_height - self.kernel_size + 1, self.stride)):\n",
    "                        for w_out, w_in in enumerate(range(0, in_width - self.kernel_size + 1, self.stride)):\n",
    "                            stride = in_channel[h_in:h_in + self.kernel_size, w_in:w_in + self.kernel_size]\n",
    "                            ker = self.kernel[c_out][c_in]\n",
    "                            output_tensor[im_idx, c_out, h_out, w_out] += (stride * ker).sum()\n",
    "        if bias: \n",
    "            output_tensor += bias\n",
    "\n",
    "        return output_tensor\n",
    "\n",
    "print(test_conv2d_layer(Conv2dLoop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Реализация через циклы очень неэффективна по производительности. Есть целых два способа сделать то же самое с помощью матричного умножения.&nbsp;</p>\n",
    "\n",
    "<p>На этом шаге будет реализация первым из них.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Рассмотрим свертку одного одноканального изображения размером 4*4 пикселя (значения пикселей обозначены через X).</p>\n",
    "\n",
    "<p>Сворачивать будем с ядром из одного фильтра размером 3*3, веса обозначены через W.</p>\n",
    "\n",
    "<p>Для простоты примем stride = 1.</p>\n",
    "\n",
    "<p>Тогда выход Y будет иметь размерность 1*1*2*2 (в данном случае на входе одно изображение - это первая единица в размерности, в ядре один фильтр - это вторая единица в размерности выхода).</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"https://ucarecdn.com/1845714a-9187-4dca-83ef-6fe44f030391/-/crop/760x275/0,198/-/preview/\"></p>\n",
    "\n",
    "<p>Оказывается, выход свертки можно получить умножением матриц, как показано ниже.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><img alt=\"\" height=\"339\" src=\"https://ucarecdn.com/e2a38490-d886-47d6-97b0-dc65f8906ba1/\" width=\"776\"></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>Рекомендуем убедиться в этом, перемножив матрицы на листочке.</strong></p>\n",
    "\n",
    "<p>Давайте перейдем от простого случая к общему:</p>\n",
    "\n",
    "<ul>\n",
    "\t<li><strong>Если фильтров в ядре больше одного.</strong> Заметим, что для каждого фильтра, матрица W’ будет умножаться на один и тот же вектор изображения. Значит, можно сконкатенировать матрицы фильтров ядра по вертикали и за одно умножение получить ответ для всех фильтров.</li>\n",
    "</ul>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><img alt=\"\" height=\"416\" src=\"https://ucarecdn.com/91757315-13b9-439c-a59d-9fa14629ce52/\" width=\"624\"></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<ul>\n",
    "\t<li><strong>Если на входе более одного изображения: </strong>заметим, что матрица W’ одинакова для всех изображений батча, то есть, можно каждое изображение вначале вытянуть в столбец, а затем эти столбцы для всех изображений батча сконкатенировать по горизонтали.</li>\n",
    "</ul>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><img alt=\"\" height=\"220\" src=\"https://ucarecdn.com/e8a10b8d-876e-44cb-ad5c-2a56abafa974/\" width=\"681\"></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<ul>\n",
    "\t<li><strong>Если в изображении больше одного слоя, </strong>вначале выполним преобразования входа и ядра для каждого слоя, а затем сконкатенируем: вектора разных слоев входа в один большой вектор, а матрицы ядра соответственно в одну длинную матрицу. И мы получим сложение от выходов по слоям в процессе перемножения матриц.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong><img alt=\"\" height=\"820\" src=\"https://lh5.googleusercontent.com/2M0cSgkwRnEMQ8y2mrnD-D2alEYn3vVsX7UrgRNLV9BbYv6nswIWesOpKjjNpPMgUl0ixOZoUVyeZXHy5Jlfy1bS4lLkrLuo2ZmOH1gYh88aMKgKa_mjrZHAWzYbBtWihg8GDrxK\" width=\"624\"></strong></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>То есть даже в самом общем случае мы за одно умножение матриц можем получить ответ.</strong></p>\n",
    "\n",
    "<p>Но рассчитанный таким способом выход не совпадает по размерности с выходом стандартного слоя из PyTorch - нужно изменить размерность.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>В коде уже реализовано:</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>\n",
    "\t<p>преобразование входного батча изображений</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p>умножение матрицы ядра на матрицу входа</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p>преобразование ответа</p>\n",
    "\t</li>\n",
    "</ul>\n",
    "\n",
    "<p>Напоминание: во всех шагах этого урока мы считаем bias в сверточных слоях нулевым.</p>\n",
    "\n",
    "<p><strong>Вам осталось реализовать преобразование ядра в описанный выше формат.</strong></p>\n",
    "\n",
    "<p><strong>Обратите внимание, что в коде рассматривается общий случай - вход состоит из нескольких многослойных изображений, в ядре несколько слоев.</strong></p></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "class Conv2dMatrix(ABCConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, dilation=1, **kwargs):\n",
    "        \"\"\"негоже без паддинга\"\"\"\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride)\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "    # Функция преобразование кернела в матрицу нужного вида.\n",
    "    def _unsqueeze_kernel(self, torch_input, output_height, output_width):\n",
    "        \"\"\"как делать не надо\"\"\"\n",
    "        *_, ker_size, ker_size = self.kernel.shape\n",
    "        *_, h, w = torch_input.shape\n",
    "        \n",
    "        kernel_unsqueezed = None\n",
    "        for ch_out_ker in self.kernel:\n",
    "            ch_out_ker_unsqueeze = None\n",
    "            \n",
    "            for ch_in_ker in ch_out_ker:\n",
    "                # добиваем 0 справа ядро вх.канала до ширины входа, вытягиваем в строку, добиваем 0 до длины вытянутого в строку входа\n",
    "                s = torch.nn.functional.pad(torch.nn.functional.pad(ch_in_ker, pad=(0,h-ker_size,0,0)).flatten(), pad=(0, h * (h-ker_size)))\n",
    "                ch_in_ker_unsqueeze = s.unsqueeze(0) # добавляем измерение в начало, чтоб могло стакаться\n",
    "\n",
    "                for i in range(max(0, h-ker_size*self.stride)):                                         # по количеству страйдов по высоте\n",
    "                    shifted = torch.roll(s, self.stride*(i+1))                                          # сдвигаем вытянутое ядро на размер страйда\n",
    "                    ch_in_ker_unsqueeze = torch.cat((ch_in_ker_unsqueeze, shifted.unsqueeze(0)), 0)     # стакаем снизу к предыдущему ядру\n",
    "                    for j in range(max(0, w-ker_size*self.stride)):                                     # по количеству страйдов по ширине\n",
    "                        shifted = torch.roll(ch_in_ker_unsqueeze, w*self.stride*(i+1))                  # сдвигаем вытянутое ядро на (размер страйда * ширину)\n",
    "                        ch_in_ker_unsqueeze = torch.cat((ch_in_ker_unsqueeze, shifted), 0)              # стакаем снизу к предыдущему ядру\n",
    "                \n",
    "                # если есть еще канальные ядра, стакаем справа\n",
    "                ch_out_ker_unsqueeze = ch_in_ker_unsqueeze if ch_out_ker_unsqueeze is None else torch.cat((ch_out_ker_unsqueeze, ch_in_ker_unsqueeze), 1)\n",
    "            # если в фильтре несколько ядер, стакаем снизу\n",
    "            kernel_unsqueezed = ch_out_ker_unsqueeze if kernel_unsqueezed is None else torch.cat((kernel_unsqueezed, ch_out_ker_unsqueeze), 0)\n",
    "\n",
    "        return kernel_unsqueezed\n",
    "\n",
    "    # Функция преобразование кернела в матрицу нужного вида.\n",
    "    def _unsqueeze_kernel(self, torch_input, output_height, output_width):\n",
    "        \"\"\"как примерно это задумывалось\"\"\"\n",
    "        _, in_channels, in_height, in_width = torch_input.shape\n",
    "        ku_size = [self.out_channels, output_height, output_width, in_channels, in_height, in_width]\n",
    "        kernel_unsqueezed = torch.zeros(ku_size, dtype=torch.float32)\n",
    "        for i in range(output_height):\n",
    "            for j in range(output_width):\n",
    "                h_slice = slice(i*self.stride, i*self.stride+self.kernel_size)\n",
    "                w_slice = slice(j*self.stride, j*self.stride+self.kernel_size)\n",
    "                kernel_unsqueezed[:, i, j, :, h_slice, w_slice] = self.kernel.type(torch.float32)\n",
    "        return kernel_unsqueezed.view(-1, in_channels*in_height*in_width)\n",
    "\n",
    "    def __call__(self, torch_input, bias=None):\n",
    "        batch_size, out_channels, output_height, output_width \\\n",
    "            = calc_out_shape(\n",
    "                input_matrix_shape=torch_input.shape,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding)\n",
    "        \n",
    "        torch_input = get_padding2d(torch_input, pad=self.padding)\n",
    "\n",
    "        kernel_unsqueezed = self._unsqueeze_kernel(torch_input, output_height, output_width)\n",
    "        result = kernel_unsqueezed @ torch_input.view((batch_size, -1)).permute(1, 0)\n",
    "\n",
    "        result = result.permute(1, 0).view((batch_size, self.out_channels,\n",
    "                                            output_height, output_width))\n",
    "                                            \n",
    "        if bias: \n",
    "            result += bias\n",
    "\n",
    "        return result\n",
    "\n",
    "print(test_conv2d_layer(Conv2dMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><p>На прошлом шаге W’ имеет много нулей. Это снижает эффективность метода.</p>\n",
    "\n",
    "<p>На этом шаге будет реализация через матрицы другим, более эффективным способом.</p>\n",
    "\n",
    "<p>Пусть в этот раз на входе батч из одного трехслойного (RGB) изображения размером 3*3.</p>\n",
    "\n",
    "<p>Пусть ядро имеет 2 фильтра шириной и высотой 2 пикселя.</p>\n",
    "\n",
    "<p>Тогда выход должен иметь размерность 1*2*2*2.</p>\n",
    "\n",
    "<p>Пусть W - веса ядра, X - значения входной матрицы, Y - значения на выходе.</p>\n",
    "\n",
    "<p>Для простоты слои изображения и слои фильтров ядра покрашены в цвета.</p>\n",
    "\n",
    "<p><strong>Обратите внимание</strong>, например, \"синяя\" X0 не обязано быть равно \"красному\" X0, аналогично и про значения в фильтрах ядра - разный цвет и одинаковые переменные могут иметь разные значения, такое обозначение выбрано, чтобы не загромождать рисунок сложными индексами.</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"https://ucarecdn.com/ddc6ccbe-2aef-4c7b-a47b-a15e67d3f6ec/\"></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Если в первом матричном способе мы вытягивали изображения в столбцы, то теперь будем вытягивать фильтры кернела в строки.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"https://ucarecdn.com/afbc3c3c-a347-4248-b0de-cd614e637fc3/\"></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>Рекомендуем проверить на листочке, что результат произведения таких матриц дает тот же результат, что и свертка.</strong></p>\n",
    "\n",
    "<p>Давайте перейдем от простого случая к общему:</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>\n",
    "\t<p><strong>Если изображений в батче больше одного</strong>: преобразования ядра от этого не меняется, а преобразованные матрицы входных изображений конкатенируются по горизонтали.</p>\n",
    "\t</li>\n",
    "</ul>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Но рассчитанный таким способом выход не совпадает по размерности с выходом стандартного слоя из PyTorch - нужно изменить размерность.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Функция умножения матриц уже реализована.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>Напоминание: во всех шагах этого урока мы считаем bias в сверточных слоях нулевым.</p>\n",
    "\n",
    "<p><strong>Требуется написать функции преобразования ядра и входа.</strong></p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "class Conv2dMatrixV2(ABCConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=0, dilation=1, **kwargs):\n",
    "        \"\"\"негоже без паддинга\"\"\"\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride)\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "    # Функция преобразования кернела в нужный формат.\n",
    "    def _convert_kernel(self):\n",
    "        # converted_kernel = torch.cat(tuple(self.kernel.flatten(2)), 0).view(self.out_channels, -1)\n",
    "        converted_kernel = self.kernel.flatten(1)   #  просто вот\n",
    "        return converted_kernel\n",
    "    \n",
    "    # Функция преобразования входа в нужный формат.\n",
    "    def _convert_input(self, torch_input, output_height, output_width):\n",
    "        converted_input=None\n",
    "        for i in range(output_height):\n",
    "            for j in range(output_width):\n",
    "                h_slice = slice(i*self.stride, i*self.stride + self.kernel_size)\n",
    "                w_slice = slice(j*self.stride, j*self.stride + self.kernel_size)\n",
    "                fs = torch_input[:, :, h_slice, w_slice].flatten().unsqueeze(0)\n",
    "                converted_input = fs if converted_input is None else torch.cat((converted_input, fs), 0)\n",
    "        converted_input = converted_input.transpose(1, 0).reshape(torch_input.shape[0], -1, output_height*output_width)\n",
    "\n",
    "        return converted_input\n",
    "\n",
    "    def _convert_input(self, torch_input, output_height, output_width): # сигнатура старая\n",
    "        *_, input_height, input_width = torch_input.shape\n",
    "\n",
    "        # индексы элементов, покрытых первым ядром первого канала певого фильтра в 2d матрице данных\n",
    "        ker_mask = input_height * torch.arange(0, self.kernel_size*self.dilation, self.dilation).unsqueeze(0).T + \\\n",
    "                                  torch.arange(0, self.kernel_size*self.dilation, self.dilation).unsqueeze(0)   \n",
    "        flat_ker_mask = ker_mask.flatten().unsqueeze(0) # в строку\n",
    "\n",
    "        # индексы смещений ядра по 2d данным, с учетом параметров свертки\n",
    "        windows = input_height * torch.arange(0, input_height - self.kernel_size*self.dilation + 1, self.stride).unsqueeze(0).T + \\\n",
    "                                 torch.arange(0, input_width - self.kernel_size*self.dilation + 1, self.stride).unsqueeze(0)\n",
    "        flat_windows = windows.flatten().unsqueeze(0)   # в строку\n",
    "\n",
    "        flat_mask = flat_windows + flat_ker_mask.T  # индексы всех элементов, покрытых ядром, в вытянутой в строку матрице 2d данных\n",
    "\n",
    "        # 2d данные - в строку; выбор данных, покрытых ядром; стакнуть вертикально\n",
    "        return torch_input.flatten(2)[:, :, flat_mask].flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "    def __call__(self, torch_input, bias=None):\n",
    "        batch_size, out_channels, output_height, output_width \\\n",
    "            = calc_out_shape(\n",
    "                input_matrix_shape=torch_input.shape,\n",
    "                out_channels=self.kernel.shape[0],\n",
    "                kernel_size=self.kernel.shape[2],\n",
    "                stride=self.stride,\n",
    "                padding=self.padding,\n",
    "                dilation=self.dilation)\n",
    "\n",
    "        torch_input = get_padding2d(torch_input, pad=self.padding)\n",
    "        \n",
    "        converted_kernel = self._convert_kernel()\n",
    "        converted_input = self._convert_input(torch_input, output_height, output_width)\n",
    "\n",
    "        conv2d_out_alternative_matrix_v2 = converted_kernel @ converted_input\n",
    "        \n",
    "        result = conv2d_out_alternative_matrix_v2.view(torch_input.shape[0],\n",
    "                                                            self.out_channels, \n",
    "                                                            output_height,\n",
    "                                                            output_width)\n",
    "        if bias: \n",
    "            result += bias\n",
    "\n",
    "        return result\n",
    "\n",
    "print(test_conv2d_layer(Conv2dMatrixV2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Сравним скорость](#toc0_)\n",
    "\n",
    "- как же я неимоверно крут!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "input_height=256\n",
    "input_width=256\n",
    "stride=3\n",
    "dilation=2\n",
    "padding=1\n",
    "\n",
    "kernel = torch.tensor(\n",
    "                      [[[[0., 1, 0],\n",
    "                         [1,  2, 1],\n",
    "                         [0,  1, 0]],\n",
    "\n",
    "                        [[1, 2, 1],\n",
    "                         [0, 3, 3],\n",
    "                         [0, 1, 10]],\n",
    "\n",
    "                        [[10, 11, 12],\n",
    "                         [13, 14, 15],\n",
    "                         [16, 17, 18]]],\n",
    "                         \n",
    "                        [[[0., 1, 1],\n",
    "                         [1,  2, 1],\n",
    "                         [0,  1, 0]],\n",
    "\n",
    "                        [[1, 2, 1],\n",
    "                         [0, 3, 3],\n",
    "                         [0, 1, 10]],\n",
    "\n",
    "                        [[10, 11, 12],\n",
    "                         [13, 14, 15],\n",
    "                         [16, 17, 18]]]])\n",
    "\n",
    "in_channels = kernel.shape[1]\n",
    "kernel_size = kernel.shape[-1]\n",
    "out_channels = kernel.shape[0]\n",
    "\n",
    "input_tensor = torch.arange(0, batch_size * in_channels *\n",
    "                               input_height * input_width,\n",
    "                               out=torch.FloatTensor()) \\\n",
    "               .reshape(batch_size, in_channels, input_height, input_width)\n",
    "\n",
    "*_, output_height, output_width = calc_out_shape(input_tensor.shape, out_channels, kernel_size, stride, padding, dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 3.12 ms, total: 34.4 ms\n",
      "Wall time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv2d_torch = Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation)\n",
    "conv2d_torch.set_kernel(kernel)\n",
    "res_torch = conv2d_torch(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98.4 ms, sys: 18.5 ms, total: 117 ms\n",
      "Wall time: 67.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv2d_matrixV2 = Conv2dMatrixV2(in_channels, out_channels, kernel_size, stride, padding, dilation)\n",
    "conv2d_matrixV2.set_kernel(kernel)\n",
    "res_matrixV2 = conv2d_matrixV2(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего лишь в 3 раза медленне чисто сишного торча. А я хорош!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2, 85, 85]), torch.Size([32, 2, 85, 85]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert torch.allclose(res_torch, res_matrixV2) \\\n",
    "              and (res_torch.shape == res_matrixV2.shape)\n",
    "res_torch.shape, res_matrixV2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  1.,  2.,  1.,  0.,  1.,  0.,  1.,  2.,  1.,  0.,  3.,\n",
       "          3.,  0.,  1., 10., 10., 11., 12., 13., 14., 15., 16., 17., 18.],\n",
       "        [ 0.,  1.,  1.,  1.,  2.,  1.,  0.,  1.,  0.,  1.,  2.,  1.,  0.,  3.,\n",
       "          3.,  0.,  1., 10., 10., 11., 12., 13., 14., 15., 16., 17., 18.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ker = conv2d_matrixV2._convert_kernel()\n",
    "ker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_mask = input_height * torch.arange(0, kernel_size*dilation, dilation).unsqueeze(0).T + torch.arange(0, kernel_size*dilation, dilation).unsqueeze(0)\n",
    "flat_ker_mask = ker_mask.flatten().unsqueeze(0)\n",
    "\n",
    "windows = input_height * torch.arange(0, input_height - kernel_size*dilation+1, stride).unsqueeze(0).T + torch.arange(0, input_width - kernel_size*dilation+1, stride).unsqueeze(0)\n",
    "flat_windows = windows.flatten().unsqueeze(0)\n",
    "\n",
    "flat_mask = flat_windows + flat_ker_mask.T\n",
    "\n",
    "# ker_mask, flat_windows, flat_mask, input_tensor[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_transform = input_tensor.flatten(2)[:, :, flat_mask].flatten(start_dim=1, end_dim=2)\n",
    "looped_transform = conv2d_matrixV2._convert_input(input_tensor, output_height, output_width)\n",
    "torch.allclose(looped_transform, masked_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Что внутре у торча в свертке?](#toc0_)\n",
    "\n",
    "класс `torch.nn,Conv2d` это обертка, которая делает паддинг, сохраняет параметры свертки и вызывает Си-функцию `F.conv2d`:\n",
    "\n",
    "    @overload\n",
    "    def conv2d(input: Tensor, weight: Tensor, bias: Optional[Tensor]=None, stride: Union[_int, _size]=1, padding: Union[_int, _size]=0, dilation: Union[_int, _size]=1, groups: _int=1) -> Tensor: ...\n",
    "\n",
    "The entry point into the C++ pytorch code for conv2d is here:\n",
    "    \n",
    "    /pytorch/aten/src/ATen/native/Convolution.cpp\n",
    "\n",
    "    at::Tensor conv2d(\n",
    "        const Tensor& input, const Tensor& weight, const Tensor& bias,\n",
    "        IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, int64_t groups) {\n",
    "    return at::convolution(input, weight, bias, stride, padding, dilation,\n",
    "                            false, {{0, 0}}, groups);\n",
    "        }\n",
    "\n",
    "\n",
    "    at::Tensor convolution(\n",
    "        const Tensor& input, const Tensor& weight, const Tensor& bias,\n",
    "        IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation,\n",
    "        bool transposed, IntArrayRef output_padding, int64_t groups) {\n",
    "    auto& ctx = at::globalContext();\n",
    "    return at::_convolution(input, weight, bias, stride, padding, dilation,\n",
    "                            transposed, output_padding, groups,\n",
    "                            ctx.benchmarkCuDNN(), ctx.deterministicCuDNN(), ctx.userEnabledCuDNN());\n",
    "        }\n",
    "\n",
    "...которая тоже обертка для диспетчирезации разных бекендов (cudnn, mkl, ) с разными конфигурациями входов 1д 2д 3д и т.п. параметров свертки.\n",
    "\n",
    "**Короче раскидано по куче функций и CPP шаблонов/классов. Общий алгоритм не понять могут не только лишь все...**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d00ba0b92f737b23b3e678e3a3ceb3fe4e948ad1ab95d9c6fdcbb4b4ec65f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
